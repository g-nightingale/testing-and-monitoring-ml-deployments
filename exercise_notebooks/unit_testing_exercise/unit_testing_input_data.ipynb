{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Unit Testing ML Code: Hands-on Exercise (Input Values)\n",
    "\n",
    "## In this notebook we will explore unit tests to validate input data using a basic schema\n",
    "\n",
    "#### We will use a classic toy dataset: the Iris plants dataset, which comes included with scikit-learn\n",
    "Dataset details: https://scikit-learn.org/stable/datasets/index.html#iris-plants-dataset\n",
    "\n",
    "As we progress through the course, the complexity of examples will increase, but we will start with something basic. This notebook is designed so that it can be run in isolation, once the setup steps described below are complete.\n",
    "\n",
    "### Setup\n",
    "\n",
    "Let's begin by importing the dataset and the libraries we are going to use. Make sure you have run `pip install -r requirements.txt` on requirements file located in the same directory as this notebook. We recommend doing this in a separate virtual environment (see dedicated setup lecture).\n",
    "\n",
    "If you need a refresher on jupyter, pandas or numpy, there are some links to resources in the section notes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn import datasets\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# Access the iris dataset from sklearn\r\n",
    "iris = datasets.load_iris()\r\n",
    "\r\n",
    "# Load the iris data into a pandas dataframe. The `data` and `feature_names`\r\n",
    "# attributes of the dataset are added by default by sklearn. We use them to\r\n",
    "# specify the columns of our dataframes.\r\n",
    "iris_frame = pd.DataFrame(iris.data, columns=iris.feature_names)\r\n",
    "\r\n",
    "# Create a \"target\" column in our dataframe, and set the values to the correct\r\n",
    "# classifications from the dataset.\r\n",
    "iris_frame['target'] = iris.target"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# View the first 5 rows of our dataframe.\r\n",
    "iris_frame.head(5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# View summary statistics for our dataframe.\r\n",
    "iris_frame.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      target  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now that we have our data loaded, we will create a simplified pipeline.\n",
    "\n",
    "This pipeline is a class for encapsulating all the related functionality for our model. As the course unfolds, we will work with more complex pipelines, including those provided by third party libraries.\n",
    "\n",
    "We train a logistic regression model to classify the flowers from the Iris dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "\r\n",
    "class SimplePipeline:\r\n",
    "    def __init__(self):\r\n",
    "        self.frame = None\r\n",
    "        # Shorthand to specify that each value should start out as\r\n",
    "        # None when the class is instantiated.\r\n",
    "        self.X_train, self.X_test, self.y_train, self.Y_test = None, None, None, None\r\n",
    "        self.model = None\r\n",
    "        self.load_dataset()\r\n",
    "    \r\n",
    "    def load_dataset(self):\r\n",
    "        \"\"\"Load the dataset and perform train test split.\"\"\"\r\n",
    "        # fetch from sklearn\r\n",
    "        dataset = datasets.load_iris()\r\n",
    "        \r\n",
    "        # remove units ' (cm)' from variable names\r\n",
    "        self.feature_names = [fn[:-5] for fn in dataset.feature_names]\r\n",
    "        self.frame = pd.DataFrame(dataset.data, columns=self.feature_names)\r\n",
    "        self.frame['target'] = dataset.target\r\n",
    "        \r\n",
    "        # we divide the data set using the train_test_split function from sklearn, \r\n",
    "        # which takes as parameters, the dataframe with the predictor variables, \r\n",
    "        # then the target, then the percentage of data to assign to the test set, \r\n",
    "        # and finally the random_state to ensure reproducibility.\r\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\r\n",
    "            self.frame[self.feature_names], self.frame.target, test_size=0.65, random_state=42)\r\n",
    "        \r\n",
    "    def train(self, algorithm=LogisticRegression):\r\n",
    "        \r\n",
    "        # we set up a LogisticRegression classifier with default parameters\r\n",
    "        self.model = algorithm(solver='lbfgs', multi_class='auto')\r\n",
    "        self.model.fit(self.X_train, self.y_train)\r\n",
    "        \r\n",
    "    def predict(self, input_data):\r\n",
    "        return self.model.predict(input_data)\r\n",
    "        \r\n",
    "    def get_accuracy(self):\r\n",
    "        \r\n",
    "        # use our X_test and y_test values generated when we used\r\n",
    "        # `train_test_split` to test accuracy.\r\n",
    "        # score is a method on the Logisitic Regression that \r\n",
    "        # returns the accuracy by default, but can be changed to other metrics, see: \r\n",
    "        # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score\r\n",
    "        return self.model.score(X=self.X_test, y=self.y_test)\r\n",
    "    \r\n",
    "    def run_pipeline(self):\r\n",
    "        \"\"\"Helper method to run multiple pipeline methods with one call.\"\"\"\r\n",
    "        self.load_dataset()\r\n",
    "        self.train()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "pipeline = SimplePipeline()\r\n",
    "pipeline.run_pipeline()\r\n",
    "accuracy_score = pipeline.get_accuracy()\r\n",
    "\r\n",
    "# note that f' string interpolation syntax requires python 3.6\r\n",
    "# https://www.python.org/dev/peps/pep-0498/\r\n",
    "print(f'current model accuracy is: {accuracy_score}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "current model accuracy is: 0.9693877551020408\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Inputs\n",
    "\n",
    "Now that we have our basic pipeline, we are in a position to test the input data.\n",
    "\n",
    "Best practice is to use a schema. A schema is a collection of rules which specify the expected values for a set of fields. Below we show a simple schema (just using a nested dictionary) for the Iris dataset. Later in the course we will look at more complex schemas, using some of the common Python libraries for data validation.\n",
    "\n",
    "The schema specifies the maximum and minimum values that can be taken by each variable. We can learn these values from the data, as we have done for this demo, or these values may come from specific domain knowledge of the subject."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "iris_schema = {\r\n",
    "    'sepal length': {\r\n",
    "        'range': {\r\n",
    "            'min': 4.0,  # determined by looking at the dataframe .describe() method\r\n",
    "            'max': 8.0\r\n",
    "        },\r\n",
    "        'dtype': float,\r\n",
    "    },\r\n",
    "    'sepal width': {\r\n",
    "        'range': {\r\n",
    "            'min': 1.0,\r\n",
    "            'max': 5.0\r\n",
    "        },\r\n",
    "        'dtype': float,\r\n",
    "    },\r\n",
    "    'petal length': {\r\n",
    "        'range': {\r\n",
    "            'min': 1.0,\r\n",
    "            'max': 7.0\r\n",
    "        },\r\n",
    "        'dtype': float,\r\n",
    "    },\r\n",
    "    'petal width': {\r\n",
    "        'range': {\r\n",
    "            'min': 0.1,\r\n",
    "            'max': 3.0\r\n",
    "        },\r\n",
    "        'dtype': float,\r\n",
    "    }\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import unittest\r\n",
    "import sys\r\n",
    "\r\n",
    "class TestIrisInputData(unittest.TestCase):\r\n",
    "    def setUp(self):\r\n",
    "        \r\n",
    "        # `setUp` will be run before each test, ensuring that you\r\n",
    "        # have a new pipeline to access in your tests. See the \r\n",
    "        # unittest docs if you are unfamiliar with unittest.\r\n",
    "        # https://docs.python.org/3/library/unittest.html#unittest.TestCase.setUp\r\n",
    "        self.pipeline = SimplePipeline()\r\n",
    "        self.pipeline.run_pipeline()\r\n",
    "    \r\n",
    "    def test_input_data_ranges(self):\r\n",
    "        # get df max and min values for each column\r\n",
    "        max_values = self.pipeline.frame.max()\r\n",
    "        min_values = self.pipeline.frame.min()\r\n",
    "        \r\n",
    "        # loop over each feature (i.e. all 4 column names)\r\n",
    "        for feature in self.pipeline.feature_names:\r\n",
    "            \r\n",
    "            # use unittest assertions to ensure the max/min values found in the dataset\r\n",
    "            # are less than/greater than those expected by the schema max/min.\r\n",
    "            self.assertTrue(max_values[feature] <= iris_schema[feature]['range']['max'])\r\n",
    "            self.assertTrue(min_values[feature] >= iris_schema[feature]['range']['min'])\r\n",
    "            \r\n",
    "    def test_input_data_types(self):\r\n",
    "        data_types = self.pipeline.frame.dtypes  # pandas dtypes method\r\n",
    "        \r\n",
    "        for feature in self.pipeline.feature_names:\r\n",
    "            self.assertEqual(data_types[feature], iris_schema[feature]['dtype'])\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# setup code to allow unittest to run the above tests inside the jupyter notebook.\r\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestIrisInputData)\r\n",
    "unittest.TextTestRunner(verbosity=1, stream=sys.stderr).run(suite)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.155s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Input Test: Hands-on Exercise\r\n",
    "Change either the schema or the input data (not the model config) so that the test fails. Do you understand why the test is failing?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "iris_schema = {\r\n",
    "    'sepal length': {\r\n",
    "        'range': {\r\n",
    "            'min': 4.0,  # determined by looking at the dataframe .describe() method\r\n",
    "            'max': 7.8\r\n",
    "        },\r\n",
    "        'dtype': float,\r\n",
    "    },\r\n",
    "    'sepal width': {\r\n",
    "        'range': {\r\n",
    "            'min': 1.0,\r\n",
    "            'max': 5.0\r\n",
    "        },\r\n",
    "        'dtype': float,\r\n",
    "    },\r\n",
    "    'petal length': {\r\n",
    "        'range': {\r\n",
    "            'min': 1.0,\r\n",
    "            'max': 7.0\r\n",
    "        },\r\n",
    "        'dtype': float,\r\n",
    "    },\r\n",
    "    'petal width': {\r\n",
    "        'range': {\r\n",
    "            'min': 0.1,\r\n",
    "            'max': 3.0\r\n",
    "        },\r\n",
    "        'dtype': float,\r\n",
    "    }\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# setup code to allow unittest to run the above tests inside the jupyter notebook.\r\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestIrisInputData)\r\n",
    "unittest.TextTestRunner(verbosity=1, stream=sys.stderr).run(suite)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "F.\n",
      "======================================================================\n",
      "FAIL: test_input_data_ranges (__main__.TestIrisInputData)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\geoff\\AppData\\Local\\Temp/ipykernel_22536/1325461213.py\", line 24, in test_input_data_ranges\n",
      "    self.assertTrue(max_values[feature] <= iris_schema[feature]['range']['max'])\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.115s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=1>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GN Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "dataset = datasets.load_iris()\r\n",
    "feature_names = [fn[:-5] for fn in dataset.feature_names]\r\n",
    "frame = pd.DataFrame(dataset.data, columns=feature_names)\r\n",
    "frame['target'] = dataset.target\r\n",
    "print(frame.max())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sepal length    7.9\n",
      "sepal width     4.4\n",
      "petal length    6.9\n",
      "petal width     2.5\n",
      "target          2.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('ml-test': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "interpreter": {
   "hash": "e7df85cb1a241f88c07e160a26584fcf3791755a9d29209fd56262f65a9d9523"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}